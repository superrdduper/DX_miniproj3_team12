# -*- coding: utf-8 -*-
"""
Day2 ì¸ë±ì‹± ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
- ëª©í‘œ: ì½”í¼ìŠ¤ ìƒì„± â†’ ì„ë² ë”© â†’ FAISS ì €ì¥ + docs.jsonl ì €ì¥
"""

import os, argparse, numpy as np
from typing import List
import pandas as pd
import time

from ingest import build_corpus, save_docs_jsonl
from embeddings import Embeddings
from store import FaissStore


def build_index(paths: List[str], index_dir: str, model: str | None = None, batch_size: int = 128):
    print("ğŸš€ [START] ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ ì‹œì‘")

    corpus = build_corpus(paths)
    if len(corpus) == 0:
        raise ValueError("âŒ ì¸ë±ì‹±í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

    texts = [item["text"] for item in corpus]
    print(f"ğŸ“„ ì´ ë¬¸ì„œ ìˆ˜: {len(texts)}ê°œ")

    emb = Embeddings(model=model, batch_size=batch_size)
    print(f"ğŸ§  ì„ë² ë”© ëª¨ë¸: {model or 'ê¸°ë³¸ê°’'}")

    # âš™ï¸ ì„ë² ë”© + ë‚´ìš© í™•ì¸
    vecs_list = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]

        # âœ… ë””ë²„ê·¸: ê° ë¬¸ì„œ ë‚´ìš© ì¼ë¶€ ì¶œë ¥
        print(f"\n=== ğŸ”¹ Batch {i // batch_size + 1} / {len(texts) // batch_size + 1} ===")
        for j, t in enumerate(batch):
            # ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ë³´ê¸° (100ì ì œí•œ)
            snippet = (t[:120] + " ...") if len(t) > 120 else t
            print(f"ğŸ“ [Doc {i + j}] {snippet}")

        vecs_batch = emb.encode(batch)
        vecs_list.append(vecs_batch)
        print(f"âœ… Batch {i + len(batch)}/{len(texts)} ì„ë² ë”© ì™„ë£Œ")

    vecs = np.vstack(vecs_list)
    print(f"âœ… ì „ì²´ ì„ë² ë”© ì™„ë£Œ! (shape={vecs.shape})")

    os.makedirs(index_dir, exist_ok=True)
    index_path = os.path.join(index_dir, "faiss.index")
    docs_path = os.path.join(index_dir, "docs.jsonl")

    store = FaissStore(dim=vecs.shape[1], index_path=index_path, docs_path=docs_path)
    store.add(vecs, corpus)
    store.save()

    save_docs_jsonl(corpus, docs_path)
    print(f"\nğŸ’¾ ì¸ë±ìŠ¤ ë° ë¬¸ì„œ ì €ì¥ ì™„ë£Œ: {index_dir}")



if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--paths", nargs="+", required=True)
    ap.add_argument("--index_dir", default="indices/day5")
    ap.add_argument("--model", default=None)
    ap.add_argument("--batch_size", type=int, default=128)
    args = ap.parse_args()

    os.makedirs(args.index_dir, exist_ok=True)

    build_index(
        paths=args.paths,
        index_dir=args.index_dir,
        model=args.model,
        batch_size=args.batch_size,
    )
